%  NOTE: Please make sure to completely fill out the \def parts in meta-data.tex!

\section*{Preface}
Some room for acknowledgements.

\input{title.tex} % Yes, again

\begin{abstract}

\end{abstract}

\section{Project Definition}

In the past, Natural Language Processing and Computer Vision efforts have been combined in order to create Visual Question Answering models. These are models which can output the right answer when given an image and a question relating to that image as input. Recently, efforts have been made in order to make these models more transparent by adding human-readable explanations to the answers that the model gives. These explanations are usually generated by training another model on the output and the internal states of the VQA model (cite mooney). These explanation generating models (EGMs) are commonly evaluated by comparing the generated explanations to human explanations \cite{wu_faithful_2019}. The aim of this project is  to develop a new, more detailed way of evaluating EGMs. This will be done by investigating what different types of errors are found in EGM explanations and categorizing them.

\section{Motivation}

Transparency has been an important concern in Data Science and it's related fields. Making models transparent is often required by law, for example in the European Union due to the conception of the GDPR \cite{noauthor_regulation_2016}, in order for humans to inspect whether decisions made by algorithm are lawful and ethical. It also has the added benefit of enabling Machine Learning Practitioners to improve their model performance (cite \& uitbreiden).

However, because of the complex mathematical nature of machine learning models, providing enough transparency is often a challenge (cite?). This is especially the case with deep neural networks (cite \& why). Recently, efforts have been made in order to make models more interpretable (more on this in the next section). Currently there have been attempts to generate explanations to complement the answers of Visual Question Answering models. The current way of evaluating these explanations and the models that generate them is to (...). In the past, it has been shown that creating a more detailed insight in the errors made by a machine learning model, we are able to more finely evaluate machine learning models in order to improve them or tune them to our preferences (cite recall en precision of iets). Therefore it is important to provide a more detailed way in which machine learning practitioners and researchers can evaluate and report on the errors made by their EGMs. 

\section{Background}



\subsection{Visual Question Answering}

A recent challenge that has been proposed by \namecite{agrawal_vqa_2016} is the free-form and open-ended task of Visual Question Answering. The goal of this task is for an artificial intelligence model to provide a natural language answer to a question about a given image. Thus this task requires a combination of natural language processing, computer vision and knowledge representation techniques.% Verder ingaan op nlp cv en kr?
The task was developed as a way to measure how new state-of-the-art techniques perform on a realistic, multi-modal task. \namecite{agrawal_vqa_2016} also provide a data set accommodating this task. The performance of a model on this task can be evaluated using accuracy (What proportion of the questions were answered correctly?)

In their paper on VQA, \namecite{agrawal_vqa_2016} also implemented several baselines to which new models that aim to complete the task can be compared: Choosing a random answer for each question, choosing the most popular answer overall for each question, choosing the most popular answer of the same question type for each question and a nearest neighbours approach. The nearest neighbours baseline got the highest accuracy on both the open ended questions (42.20\%) and multiple choice questions (48\%) They also implemented a model that already reached a 57.75\% accuracy on the open ended questions and a 62.70\% accuracy on the multiple choice questions. At the time of writing this proposal, the LXMERT model by \namecite{tan_lxmert_2019} has achieved state-of-the-art with an overall accuracy of 74\%.%uitleggen hoe? Verder Uitbreiden?


\subsection{Transparency methods}



\subsection{Explanations}


\section{Dataset}
The VQA model will be trained on the VQA v2 dataset (cite). %Why?, What size is it? Give some explaination on how it is designed and why it is the best for this purpose.%
The EGM will be trained on the VQA-X dataset. (cite here).  %same as above%


\section{Algorithms \& Software}



\section{Evaluation Method}


\section{Planning}

\input{bib-apx.tex}